# ğŸ½ï¸ Voice-Enabled GenAI Restaurant Assistant (MVP)

> **AI-powered receptionist for restaurants** â€” built with **FastAPI + Ollama**.
> This MVP provides a text-based conversational assistant able to take reservations, answer menu questions, and simulate customer interactions.
> Voice interactions, RAG (menu info), and multi-agent orchestration will be added in later versions.

---

## ğŸš€ Features (Current MVP)

âœ” Conversational restaurant assistant
âœ” Takes reservations through natural language
âœ” Answers menu + general questions
âœ” Runs locally with **Ollama** (free, open-source models)
âœ” Simple API endpoint (`/api/chat`)
âœ” Reproducible and documented

> ğŸ’¡ Next steps (future updates): Voice, RAG, Multi-Agents, Streamlit UI

---

## ğŸ—ï¸ Tech Stack

| Component          | Technology                  |
| ------------------ | --------------------------- |
| Backend            | FastAPI                     |
| LLM Inference      | Ollama (default: `mistral`) |
| HTTP Requests      | httpx                       |
| Deployment (later) | Docker                      |
| UI (later)         | Streamlit                   |

---

## ğŸ“‚ Project Structure

```
genai-restaurant-assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_client.py      # LLM call wrapper for Ollama
â”‚   â””â”€â”€ api.py             # FastAPI REST endpoints
â”‚
â”œâ”€â”€ main.py                # FastAPI entrypoint
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Installation

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Install Ollama (if not installed)

[https://ollama.com/download](https://ollama.com/download)

Then pull a model (ex: Mistral)

```bash
ollama pull mistral
```

---

## â–¶ï¸ Run the Application

Start FastAPI server:

```bash
uvicorn main:app --reload
```

The API will be available at:

```
http://localhost:8000/api/chat
```

---

## ğŸ“¡ Example API Call

### Using `curl`

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
        "message": "I want to book a table for 4 tonight at 8pm",
        "history": []
      }'
```

### Example Response

```json
{
  "reply": "Sure! Can I have your name for the reservation?"
}
```

---

## ğŸ“ License

This project uses open-source, academic-friendly LLMs and tools.
You are free to use, modify, and distribute under **MIT License**.
